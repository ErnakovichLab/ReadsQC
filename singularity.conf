# This is an example of how you can use Docker only workflows as a Cromwell
# backend provider. *This is not a complete configuration file!* The
# content here should be copy pasted into the backend -> providers section
# of the cromwell.examples.conf in the root of the repository. You should
# uncomment lines that you want to define, and read carefully to customize
# the file. If you have any questions, please open an issue at
# https://www.github.com/broadinstitute/cromwell/issues

# Documentation
# This backend doesn't have an official page, but you can read about general
# Docker use here: https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#docker
# If you want to use containers, the other sections on that page will be useful to you.

#backend {
#  default = "Local"

#  providers {

#    # Example backend that _only_ runs workflows that specify docker for every command.
#    Local {
#      config {
#        run-in-background = true
#        runtime-attributes = """
#        String? docker
#        String? docker_user = "$EUID" 
#        String? database
#        """
#        
#        submit = "/bin/bash ${script}"
#        #--volume ${cwd}:${docker_cwd} \
#        submit-docker = """
#		LOOKUP=$(shifterimg lookup ${docker})
#		if [[ ! $LOOKUP ]]; then
#			shifterimg pull ${docker}
#		fi
#
#		shifter --image=docker:${docker} \
#			${"--volume " + database + ":/databases"} \
#			${job_shell} ${docker_script}
#        """
#
#	dockerRoot = /global/cfs/cdirs/m3408/aim2/rqc_filter/cromwell-executions
#        filesystems {
#          local {
#            localization: [
#              "hard-link", "soft-link", "copy"
#            ]
#            caching {
#              duplication-strategy: [
#                "hard-link", "soft-link", "copy"
#              ]
#            }
#          }
#        }    
#     
#      }
#    }
#  }
#}


# Documentation
# https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#singularity

backend {
  default = singularity

  providers {
    singularity {
      # The backend custom configuration.
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"

      config {
        run-in-background = true
	# Adding data location to runtime attributes, so both cwd and the location of data are bound to singularity
        runtime-attributes = """
              String? docker
	      String? docker_user = "$EUID"
             # String? datdir = "$PWD/test"
              String? data_dir
              String? dbdir
            """
        submit = "/bin/bash ${script}"
        submit-docker = """
               LOOKUP=$(singularity inspect ${docker})
               if [[ ! $LOOKUP ]]; then
                       singularity pull ${docker}
               fi
               
               singularity exec --containall --bind ${dbdir},${data_dir},${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_script}
        """
	# Root directory where Cromwell writes job results in the container. This value
        # can be used to specify where the execution folder is mounted in the container.
        # it is used for the construction of the docker_cwd string in the submit-docker
        # value above. DOCKER ROOT MUST BE A FULL PATH!! NO abbreviations!
       dockerRoot = "/mnt/home/ernakovich/heh1030/Software/ReadsQC/cromwell-executions"
filesystems {
          local {
            # When localizing a file, what type of file duplication should occur. 
            # possible values: "hard-link", "soft-link", "copy", "cached-copy".
            # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem
            localization: [
              "hard-link", "soft-link", "copy"
            ]

            caching {
              # When copying a cached result, what type of file duplication should occur. 
              # possible values: "hard-link", "soft-link", "copy", "cached-copy".
              # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem
              # Attempted in the order listed below:
              duplication-strategy: [
                "hard-link", "soft-link", "copy"
              ]
            }
          }
        }
      }
    }
  }
}




docker {
  hash-lookup {
    enabled = false
    # Set this to match your available quota against the Google Container Engine API
    #gcr-api-queries-per-100-seconds = 1000

    # Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again
    #cache-entry-ttl = "20 minutes"

    # Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache
    #cache-size = 200

    # How should docker hashes be looked up. Possible values are "local" and "remote"
    # "local": Lookup hashes on the local docker daemon using the cli
    # "remote": Lookup hashes on docker hub and gcr
    method = "local"
  }
}
